{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from __future__ import unicode_literals\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def amazon_job(number_page=10):\n",
    "    \"\"\"\n",
    "    retrieve job title, job location, job posting date, and job link from every page in \n",
    "    https://amazon.jobs.\n",
    "\n",
    "    Arguments:\n",
    "    number_page -- Number of pages that one wish to retrive the data from.\n",
    "\n",
    "    Return:\n",
    "    s -- A tuple including all the job infromation for each job in each page\n",
    "    \"\"\"\n",
    "    \n",
    "    job_title=[]\n",
    "    location=[]\n",
    "    posting_date=[]\n",
    "    job_link=[]\n",
    "\n",
    "    for i in range(number_page):\n",
    "        driver=webdriver.Chrome('/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/chromedriver')\n",
    "        \n",
    "        #There are 10 job postings in each page. Therefore, job pages URL can be updated\n",
    "        #by muliplying the counter (\"i\") by 10.\n",
    "        URL='https://www.amazon.jobs/en/search?offset=\"+str(10*i)+\"&result_limit=10&sort=relevant&job_type%5B%5D=Full-Time&business_category%5B%5D=amazon-web-services&distanceType=Mi&radius=24km&latitude=&longitude=&loc_group_id=&loc_query=&base_query=data%20engineer&city=&country=&region=&county=&query_options=&'\n",
    "    \n",
    "        driver.get(URL)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "         \n",
    "        job_title.append([td.find('h3').text for td in soup.findAll(\"div\", {\"class\": \"job-tile\"})])\n",
    "        posting_date.append([re.sub('Posted ', '', td.text) for td in soup.findAll(\"h2\", {\"class\": \"posting-date\"})])\n",
    "        job_link.append(['https://www.amazon.jobs'+td.find('a').get('href') for td in soup.findAll(\"div\", {\"class\": \"job-tile\"})])\n",
    "        \n",
    "           \n",
    "        \n",
    "    return job_title,location,posting_date,job_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extracting jobs information. Currently there are 346 pages in amazon.job. \n",
    "job=amazon_job(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_list(job):\n",
    "    \"\"\"\n",
    "    put all the job data in alist that can be used to create a DataFrame\n",
    "\n",
    "    Arguments:\n",
    "    job_list -- A tuple containing job title, job location, job posting date, and job link .\n",
    "\n",
    "    Return:\n",
    "    s -- A list containing job information\n",
    "    \"\"\"\n",
    "    t=[]\n",
    "    for i in job:\n",
    "        for b in i:\n",
    "            for c in b:\n",
    "                t.append(c)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Engineer', 'Data Engineer', 'Data Engineer', 'Data Engineer', 'Sr. Data Engineer, Data Solutions & Engineering, Security', 'Data Engineer, Data Solutions & Engineering, Security', 'Data Engineer, AWS Econ Data', 'Data Engineer, AWS Econ Data', 'Data Engineer, AWS Econ Data', 'Data Engineer', 'October 12, 2021', 'April 25, 2022', 'December  7, 2021', 'January  5, 2021', 'October 27, 2021', 'October 27, 2021', 'March 25, 2022', 'March 14, 2022', 'December 10, 2021', 'April 19, 2021', 'https://www.amazon.jobs/en/jobs/1770158/data-engineer', 'https://www.amazon.jobs/en/jobs/2037947/data-engineer', 'https://www.amazon.jobs/en/jobs/1841062/data-engineer', 'https://www.amazon.jobs/en/jobs/1391585/data-engineer', 'https://www.amazon.jobs/en/jobs/1791167/sr-data-engineer-data-solutions-engineering-security', 'https://www.amazon.jobs/en/jobs/1791166/data-engineer-data-solutions-engineering-security', 'https://www.amazon.jobs/en/jobs/1999795/data-engineer-aws-econ-data', 'https://www.amazon.jobs/en/jobs/1981936/data-engineer-aws-econ-data', 'https://www.amazon.jobs/en/jobs/1845677/data-engineer-aws-econ-data', 'https://www.amazon.jobs/en/jobs/1524485/data-engineer']\n"
     ]
    }
   ],
   "source": [
    "#make a list of all job data\n",
    "job_list=make_list(job)\n",
    "len(job_list)\n",
    "print(job_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a dataframe from the job information list\n",
    "def make_dataframe(job_list):\n",
    "    \"\"\"\n",
    "    ceate a dataframe from the job_list\n",
    "    \n",
    "    Arguments:\n",
    "    job_list -- A tuple containing job title, job location, job posting date, and job link .\n",
    "\n",
    "    Return:\n",
    "    df -- A dataframe containing each job description, basic qualification and preferred qualification.\n",
    "    \"\"\"\n",
    "    \n",
    "    l=int(len(job_list))\n",
    "    df=pd.DataFrame(OrderedDict({'Title': job_list[:l],'Posting_date':job_list[2*l:3*l], 'job_link': job_list[3*l:]}))\n",
    "    \n",
    "    print(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0                                       Data Engineer\n",
      "1                                       Data Engineer\n",
      "2                                       Data Engineer\n",
      "3                                       Data Engineer\n",
      "4   Sr. Data Engineer, Data Solutions & Engineerin...\n",
      "5   Data Engineer, Data Solutions & Engineering, S...\n",
      "6                        Data Engineer, AWS Econ Data\n",
      "7                        Data Engineer, AWS Econ Data\n",
      "8                        Data Engineer, AWS Econ Data\n",
      "9                                       Data Engineer\n",
      "10                                   October 12, 2021\n",
      "11                                     April 25, 2022\n",
      "12                                  December  7, 2021\n",
      "13                                   January  5, 2021\n",
      "14                                   October 27, 2021\n",
      "15                                   October 27, 2021\n",
      "16                                     March 25, 2022\n",
      "17                                     March 14, 2022\n",
      "18                                  December 10, 2021\n",
      "19                                     April 19, 2021\n",
      "20  https://www.amazon.jobs/en/jobs/1770158/data-e...\n",
      "21  https://www.amazon.jobs/en/jobs/2037947/data-e...\n",
      "22  https://www.amazon.jobs/en/jobs/1841062/data-e...\n",
      "23  https://www.amazon.jobs/en/jobs/1391585/data-e...\n",
      "24  https://www.amazon.jobs/en/jobs/1791167/sr-dat...\n",
      "25  https://www.amazon.jobs/en/jobs/1791166/data-e...\n",
      "26  https://www.amazon.jobs/en/jobs/1999795/data-e...\n",
      "27  https://www.amazon.jobs/en/jobs/1981936/data-e...\n",
      "28  https://www.amazon.jobs/en/jobs/1845677/data-e...\n",
      "29  https://www.amazon.jobs/en/jobs/1524485/data-e...\n"
     ]
    }
   ],
   "source": [
    "#DataFrame containing job title, job location, job posting date, and job link.\n",
    "df1=pd.DataFrame(job_list)\n",
    "df1.transpose()\n",
    "df1.to_csv('df1.csv')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def job_description(job_list):\n",
    "    \"\"\"\n",
    "    retrieving job description, basic qualification and preferred qualification.\n",
    "    we get the job link from the previous job_list and then this function goes to every posted job\n",
    "    page to get each job description, basic qualification and preferred qualification.\n",
    "\n",
    "    Arguments:\n",
    "    job_list -- A tuple containing job title, job location, job posting date, and job link .\n",
    "\n",
    "    Return:\n",
    "    job_information -- A list containing each job description, basic qualification and preferred qualification.\n",
    "    \"\"\"\n",
    "    \n",
    "    l=int(len(job_list)/4)\n",
    "    job_link=job_list[3*l:]\n",
    "    job_information=[]\n",
    "    \n",
    "    \n",
    "    for x in range(l):\n",
    "        driver=webdriver.Chrome('/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/chromedriver')\n",
    "        URL=job_link[x]\n",
    "        driver.get(URL)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "        job_information.append([h2.next_sibling.text for h2 in soup.findAll(\"h2\")])\n",
    "        \n",
    "    return job_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000008?line=0'>1</a>\u001b[0m job_description\u001b[39m=\u001b[39mjob_description(job_list)\n",
      "\u001b[1;32m/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb Cell 8'\u001b[0m in \u001b[0;36mjob_description\u001b[0;34m(job_list)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=24'>25</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(driver\u001b[39m.\u001b[39mpage_source, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=26'>27</a>\u001b[0m     driver\u001b[39m.\u001b[39mquit()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=28'>29</a>\u001b[0m     job_information\u001b[39m.\u001b[39mappend([p\u001b[39m.\u001b[39mnext_sibling\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m\"\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m job_information\n",
      "\u001b[1;32m/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb Cell 8'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=24'>25</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(driver\u001b[39m.\u001b[39mpage_source, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=26'>27</a>\u001b[0m     driver\u001b[39m.\u001b[39mquit()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=28'>29</a>\u001b[0m     job_information\u001b[39m.\u001b[39mappend([p\u001b[39m.\u001b[39;49mnext_sibling\u001b[39m.\u001b[39;49mtext \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mfindAll(\u001b[39m\"\u001b[39m\u001b[39mp\u001b[39m\u001b[39m\"\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zariyahowie/Documents/DS4A/team_project/Amazon_jobs-master/amazon_jobs.ipynb#ch0000007?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m job_information\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "job_description=job_description(job_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe from the job description, basic qualification and preferred qualification\n",
    "df2=pd.DataFrame(job_description)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#combining the two dataframes and save them in a csv file\n",
    "result = pd.concat([df1[['Title','location','Posting_date']], df2[['DESCRIPTION','BASIC QUALIFICATIONS','PREFERRED QUALIFICATIONS']]], axis=1, join='inner')\n",
    "result.to_csv('full_job_amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_job=amazon_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ful_job=make_list(ful_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=make_dataframe(ful_job2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ful_job_de=job_description(ful_job2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(ful_job_de, columns=['DESCRIPTION','BASIC QUALIFICATIONS','PREFERRED QUALIFICATIONS'])\n",
    "\n",
    "df2.to_csv('job_link_des.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([df1[['Title','location','Posting_date']], df2[['DESCRIPTION','BASIC QUALIFICATIONS','PREFERRED QUALIFICATIONS']]], axis=1, join='inner')\n",
    "result.to_csv('full_job_amazon_new.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
